#!/usr/bin/env python3
"""
DINOv2 vs DINOv3 RoMa ëª¨ë¸ ê°„ë‹¨ ë¹„êµ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (100ê°œ ëœë¤ ìƒ˜í”Œ)
"""

import os
import sys
import json
import cv2
import numpy as np
import torch
import random
from PIL import Image
from tqdm import tqdm

# ============================================================================
# ì„¤ì • (Configuration)
# ============================================================================
class Config:
    # --- ë°ì´í„° ë° ëª¨ë¸ ê²½ë¡œ ---
    DATA_DIR = "./processed_refine_data"  # ì „ì²˜ë¦¬ëœ ë°ì´í„° í´ë”
    LABEL_MAPPING_FILE = os.path.join(DATA_DIR, "label_mapping.json")
    
    # --- í‰ê°€ ì„¤ì • ---
    TARGET_SIZE = 512  # ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆí•  í¬ê¸°
    RANSAC_THRESHOLD = 3.0  # RANSAC ì´ìƒì¹˜ ì œê±° ì„ê³„ê°’
    MIN_MATCHES = 8  # Homography ì¶”ì •ì„ ìœ„í•œ ìµœì†Œ ë§¤ì¹­ ìˆ˜
    NUM_RANDOM_SAMPLES = 100  # ëœë¤ ìƒ˜í”Œ ìˆ˜

    # --- í‰ê°€ì§€í‘œ ì„ê³„ê°’ ---
    PCK_THRESHOLDS = [1, 3, 5]  # PCK ê³„ì‚°ì„ ìœ„í•œ í”½ì…€ ì„ê³„ê°’


# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Utility Functions)
# ============================================================================
def load_json_file(filepath):
    """JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"File not found: {filepath}")
    with open(filepath, 'r') as f:
        return json.load(f)

def get_random_samples(data_dir, num_samples=100):
    """ë°ì´í„°ì…‹ì—ì„œ ëœë¤ ìƒ˜í”Œì„ ì„ ì •í•©ë‹ˆë‹¤."""
    # ëª¨ë“  pair ë””ë ‰í† ë¦¬ ì°¾ê¸°
    pair_dirs = [d for d in os.listdir(data_dir) if d.startswith('pair_')]
    pair_dirs.sort()
    
    print(f"ì´ {len(pair_dirs)}ê°œì˜ pair ì¤‘ì—ì„œ {num_samples}ê°œë¥¼ ëœë¤ìœ¼ë¡œ ì„ ì •í•©ë‹ˆë‹¤.")
    
    # ëœë¤ ìƒ˜í”Œë§
    random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì‹œë“œ ì„¤ì •
    selected_pairs = random.sample(pair_dirs, min(num_samples, len(pair_dirs)))
    
    # pair ë²ˆí˜¸ ì¶”ì¶œ
    selected_indices = []
    for pair_dir in selected_pairs:
        pair_num = int(pair_dir.split('_')[1])
        selected_indices.append(pair_num)
    
    selected_indices.sort()
    
    print(f"ì„ ì •ëœ ìƒ˜í”Œ: {selected_indices[:10]}... (ì´ {len(selected_indices)}ê°œ)")
    
    return selected_indices

def parse_label_file(filepath):
    """ë¼ë²¨ íŒŒì¼ì—ì„œ ëŒ€ì‘ì  ì¢Œí‘œë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        points = []
        with open(filepath, 'r') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line and not line.startswith('#'):
                    parts = line.split()
                    if len(parts) >= 2:
                        try:
                            # í˜•ì‹: "1 296.0030653586301, 188.0888049593124"
                            if len(parts) >= 3:
                                x_str = parts[1].rstrip(',')  # ì½¤ë§ˆ ì œê±°
                                y_str = parts[2]
                                x, y = float(x_str), float(y_str)
                                points.append([x, y])
                        except (ValueError, IndexError) as e:
                            continue
        return np.array(points) if points else None
    except Exception as e:
        return None

def get_gt_homography_from_labels(pair_idx, label_mapping, target_size, base_dir="."):
    """ë¼ë²¨ íŒŒì¼ì—ì„œ GT í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        pair_key = str(pair_idx)
        if pair_key not in label_mapping:
            return None, None, None
        
        labels = label_mapping[pair_key]
        
        # ë¼ë²¨ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        kompsat_filename = os.path.basename(labels['kompsat_label'])
        google_filename = os.path.basename(labels['google_label'])
        
        kompsat_label_path = os.path.join(base_dir, "labels", kompsat_filename)
        google_label_path = os.path.join(base_dir, "labels", google_filename)
        
        # ë¼ë²¨ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not (os.path.exists(kompsat_label_path) and os.path.exists(google_label_path)):
            return None, None, None
        
        # ëŒ€ì‘ì  ë¡œë“œ
        k_points = parse_label_file(kompsat_label_path)
        g_points = parse_label_file(google_label_path)
        
        if k_points is None or g_points is None:
            return None, None, None
        
        # ì  ê°œìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš° ë” ì ì€ ê°œìˆ˜ì— ë§ì¶¤
        min_points = min(len(k_points), len(g_points))
        if min_points < 4:
            return None, None, None
        
        # ë” ì ì€ ê°œìˆ˜ë§Œí¼ë§Œ ì‚¬ìš©
        k_points = k_points[:min_points]
        g_points = g_points[:min_points]
        
        # RANSACì„ ì‚¬ìš©í•´ì„œ ì´ìƒì¹˜ ì œê±° ë° í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •
        best_H = None
        best_mask = None
        best_inliers = 0
        
        for threshold in [5.0, 8.0, 12.0]:
            H, mask = cv2.findHomography(g_points, k_points, cv2.RANSAC, threshold)
            if H is not None and mask is not None:
                inliers = np.sum(mask)
                if inliers > best_inliers and inliers >= 6:
                    best_H = H
                    best_mask = mask
                    best_inliers = inliers
        
        if best_H is None or best_inliers < 6:
            return None, None, None
        
        # RANSACìœ¼ë¡œ ì„ íƒëœ inlierë“¤ë§Œ ì‚¬ìš©
        inlier_indices = np.where(best_mask.ravel())[0]
        k_points_filtered = k_points[inlier_indices]
        g_points_filtered = g_points[inlier_indices]
        
        # í•„í„°ë§ëœ ì ë“¤ë¡œ ìµœì¢… í˜¸ëª¨ê·¸ë˜í”¼ ì¬ê³„ì‚°
        H_gt, _ = cv2.findHomography(g_points_filtered, k_points_filtered, 0)
        
        if H_gt is None:
            return None, None, None
        
        # GT ì¢Œí‘œë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
        original_size = 1000
        scale_factor = target_size / original_size
        
        g_points_scaled = g_points_filtered * scale_factor
        k_points_scaled = k_points_filtered * scale_factor
        
        # í˜¸ëª¨ê·¸ë˜í”¼ë„ ìŠ¤ì¼€ì¼ë§ì— ë§ê²Œ ì¡°ì •
        H_gt_scaled = H_gt.copy()
        H_gt_scaled[0, 2] *= scale_factor
        H_gt_scaled[1, 2] *= scale_factor
            
        return H_gt_scaled, g_points_scaled, k_points_scaled
        
    except Exception as e:
        return None, None, None

def calculate_metrics(H_pred, gt_points_source, gt_points_target):
    """í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ìŒì— ëŒ€í•œ ëª¨ë“  í‰ê°€ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if H_pred is None or gt_points_source is None:
        return None

    # GT ì¢Œí‘œë¥¼ H_predë¡œ ë³€í™˜í•˜ì—¬ ì˜ˆì¸¡ ì¢Œí‘œ ìƒì„±
    gt_source_h = np.hstack([gt_points_source, np.ones((len(gt_points_source), 1))])
    pred_target_h = (H_pred @ gt_source_h.T).T
    pred_target_points = pred_target_h[:, :2] / pred_target_h[:, 2:3]
    
    # í”½ì…€ ì˜¤ì°¨ ê³„ì‚°
    errors = np.linalg.norm(pred_target_points - gt_points_target, axis=1)
    
    # í‰ê°€ì§€í‘œ ê³„ì‚°
    rmse = np.sqrt(np.mean(errors ** 2))
    
    pck_metrics = {}
    for t in Config.PCK_THRESHOLDS:
        pck_metrics[f'pck@{t}px'] = (errors < t).mean() * 100
    
    metrics = {
        'rmse': rmse,
        'mean_error': np.mean(errors),
        'median_error': np.median(errors),
        'std_error': np.std(errors),
        **pck_metrics,
    }
    return metrics

def evaluate_model(model, test_indices, label_mapping, device, model_name, base_dir="."):
    """ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤."""
    
    print(f"\n{'='*80}")
    print(f"ğŸ”„ {model_name} í‰ê°€ ì‹œì‘")
    print('='*80)
    
    model.eval()
    print(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    all_results = []
    
    for pair_idx in tqdm(test_indices, desc=f"{model_name} í‰ê°€"):
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
            pair_dir = os.path.join(base_dir, 'processed_refine_data', f'pair_{pair_idx:04d}')
            img_source = cv2.cvtColor(cv2.imread(os.path.join(pair_dir, 'google.jpg')), cv2.COLOR_BGR2RGB)
            img_target = cv2.cvtColor(cv2.imread(os.path.join(pair_dir, 'kompsat.jpg')), cv2.COLOR_BGR2RGB)
            
            h, w = img_source.shape[:2]
            
            # GT Homography ë° GT ì¢Œí‘œ ë¡œë“œ
            _, gt_source_pts, gt_target_pts = get_gt_homography_from_labels(pair_idx, label_mapping, Config.TARGET_SIZE, base_dir=base_dir)
            if gt_source_pts is None:
                continue

            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                warp, certainty = model.match(Image.fromarray(img_source), Image.fromarray(img_target), device=device)
                matches, _ = model.sample(warp, certainty)
            
            if matches is None or len(matches) == 0:
                continue
                
            kps_source, kps_target = model.to_pixel_coordinates(matches, h, w, h, w)
            kps_source = kps_source.cpu().numpy()
            kps_target = kps_target.cpu().numpy()

            if len(kps_source) < Config.MIN_MATCHES:
                continue
            
            # ì˜ˆì¸¡ Homography ì¶”ì •
            H_pred, _ = cv2.findHomography(kps_source, kps_target, cv2.RANSAC, Config.RANSAC_THRESHOLD)
            
            # í‰ê°€ì§€í‘œ ê³„ì‚°
            metrics = calculate_metrics(H_pred, gt_source_pts, gt_target_pts)
            if metrics:
                metrics['model_name'] = model_name
                all_results.append(metrics)

        except Exception as e:
            if pair_idx < 10:
                print(f"  ìƒ˜í”Œ {pair_idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue
            
    print(f"âœ… {model_name} í‰ê°€ ì™„ë£Œ: {len(all_results)}ê°œ ìƒ˜í”Œ")
    return all_results

def print_comparison_results(original_results, dinov3_results):
    """ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
    
    print(f"\n{'='*80}")
    print("ğŸ“Š ì›ë³¸ RoMa (DINOv2) vs DINOv3 RoMa ë¹„êµ ê²°ê³¼")
    print('='*80)
    
    print(f"\nValid samples:")
    print(f"  ì›ë³¸ RoMa (DINOv2): {len(original_results)}")
    print(f"  DINOv3 RoMa: {len(dinov3_results)}")
    
    if len(original_results) == 0 and len(dinov3_results) == 0:
        print("\nâš ï¸  No valid results!")
        return
    
    # ê° ëª¨ë¸ë³„ í†µê³„ ê³„ì‚°
    models_data = []
    
    for name, results in [
        ("ì›ë³¸ RoMa (DINOv2)", original_results),
        ("DINOv3 RoMa", dinov3_results)
    ]:
        if len(results) == 0:
            models_data.append({
                'name': name,
                'count': 0,
                'rmse_mean': None,
                'rmse_std': None,
                'rmse_median': None,
                'pck_1px': None,
                'pck_3px': None,
                'pck_5px': None,
            })
            continue
        
        # í†µê³„ ê³„ì‚°
        rmses = [r['rmse'] for r in results]
        pck_1px = [r['pck@1px'] for r in results]
        pck_3px = [r['pck@3px'] for r in results]
        pck_5px = [r['pck@5px'] for r in results]
        
        models_data.append({
            'name': name,
            'count': len(results),
            'rmse_mean': np.mean(rmses),
            'rmse_std': np.std(rmses),
            'rmse_median': np.median(rmses),
            'pck_1px': np.mean(pck_1px),
            'pck_3px': np.mean(pck_3px),
            'pck_5px': np.mean(pck_5px),
        })
    
    # í‘œ í˜•ì‹ ì¶œë ¥
    print(f"\n{'='*80}")
    print("ğŸ“Š ì„±ëŠ¥ ë¹„êµí‘œ (Performance Comparison Table)")
    print('='*80)
    
    # í—¤ë”
    print(f"\n{'Metric':<40} | {'ì›ë³¸ RoMa (DINOv2)':>20} | {'DINOv3 RoMa':>15}")
    print('-' * 85)
    
    # ìƒ˜í”Œ ìˆ˜
    print(f"{'Valid Samples':<40} | {models_data[0]['count']:>20} | {models_data[1]['count']:>15}")
    print('-' * 85)
    
    # RMSE
    if models_data[0]['rmse_mean'] is not None and models_data[1]['rmse_mean'] is not None:
        print(f"{'RMSE Mean (px)':<40} | {models_data[0]['rmse_mean']:>19.2f} | {models_data[1]['rmse_mean']:>14.2f}")
        print(f"{'RMSE Std Dev (px)':<40} | {models_data[0]['rmse_std']:>19.2f} | {models_data[1]['rmse_std']:>14.2f}")
        print(f"{'RMSE Median (px)':<40} | {models_data[0]['rmse_median']:>19.2f} | {models_data[1]['rmse_median']:>14.2f}")
    else:
        print(f"{'RMSE Mean (px)':<40} | {'N/A':>20} | {'N/A':>15}")
    print('-' * 85)
    
    # PCK
    if models_data[0]['pck_1px'] is not None and models_data[1]['pck_1px'] is not None:
        print(f"{'PCK@1px (%)':<40} | {models_data[0]['pck_1px']:>19.2f} | {models_data[1]['pck_1px']:>14.2f}")
        print(f"{'PCK@3px (%)':<40} | {models_data[0]['pck_3px']:>19.2f} | {models_data[1]['pck_3px']:>14.2f}")
        print(f"{'PCK@5px (%)':<40} | {models_data[0]['pck_5px']:>19.2f} | {models_data[1]['pck_5px']:>14.2f}")
    else:
        print(f"{'PCK@1px (%)':<40} | {'N/A':>20} | {'N/A':>15}")
    
    print('='*85)
    
    # ì„±ëŠ¥ ê°œì„  ìš”ì•½
    if models_data[1]['rmse_mean'] is not None and models_data[0]['rmse_mean'] is not None:
        print(f"\n{'='*80}")
        print("ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ìš”ì•½ (Performance Improvement Summary)")
        print('='*80)
        
        rmse_improvement = ((models_data[0]['rmse_mean'] - models_data[1]['rmse_mean']) / models_data[0]['rmse_mean']) * 100
        pck_1px_improvement = models_data[1]['pck_1px'] - models_data[0]['pck_1px']
        pck_3px_improvement = models_data[1]['pck_3px'] - models_data[0]['pck_3px']
        pck_5px_improvement = models_data[1]['pck_5px'] - models_data[0]['pck_5px']
        
        print(f"\nì›ë³¸ RoMa (DINOv2) â†’ DINOv3 RoMa:")
        print(f"  RMSE: {models_data[0]['rmse_mean']:.2f}px â†’ {models_data[1]['rmse_mean']:.2f}px ({rmse_improvement:+.2f}%)")
        print(f"  PCK@1px: {models_data[0]['pck_1px']:.2f}% â†’ {models_data[1]['pck_1px']:.2f}% ({pck_1px_improvement:+.2f}%p)")
        print(f"  PCK@3px: {models_data[0]['pck_3px']:.2f}% â†’ {models_data[1]['pck_3px']:.2f}% ({pck_3px_improvement:+.2f}%p)")
        print(f"  PCK@5px: {models_data[0]['pck_5px']:.2f}% â†’ {models_data[1]['pck_5px']:.2f}% ({pck_5px_improvement:+.2f}%p)")
        
        print('='*80)

# ============================================================================
# ë©”ì¸ í‰ê°€ í•¨ìˆ˜ (Main Evaluation Function)
# ============================================================================
def compare_models():
    # --- 1. ì´ˆê¸° ì„¤ì • ---
    print("=" * 80)
    print("ğŸš€ ì›ë³¸ RoMa (DINOv2) vs DINOv3 RoMa ë¹„êµ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    print(f"ğŸ“Š ëœë¤ ìƒ˜í”Œ ìˆ˜: {Config.NUM_RANDOM_SAMPLES}ê°œ")
    print("=" * 80)
    
    # ë‹¤ë¥¸ GPU ì‚¬ìš© (GPU 2ë²ˆ ì‚¬ìš© - ê±°ì˜ ë¹„ì–´ìˆìŒ)
    if torch.cuda.is_available():
        if torch.cuda.device_count() > 2:
            device = torch.device('cuda:2')  # GPU 2ë²ˆ ì‚¬ìš© (ê±°ì˜ ë¹„ì–´ìˆìŒ)
            print(f"ì‚¬ìš© ì¥ì¹˜: {device} (GPU 2ë²ˆ - ê±°ì˜ ë¹„ì–´ìˆìŒ)")
        else:
            device = torch.device('cuda:0')
            print(f"ì‚¬ìš© ì¥ì¹˜: {device} (GPU 0ë²ˆ)")
    else:
        device = torch.device('cpu')
        print(f"ì‚¬ìš© ì¥ì¹˜: {device}")
    
    # --- 2. ëœë¤ ìƒ˜í”Œ ì„ ì • ---
    print("\n[1/4] ëœë¤ ìƒ˜í”Œ ì„ ì • ì¤‘...")
    test_indices = get_random_samples(Config.DATA_DIR, Config.NUM_RANDOM_SAMPLES)
    
    # ë¼ë²¨ ë§¤í•‘ ë¡œë“œ
    label_mapping = load_json_file(Config.LABEL_MAPPING_FILE)
    
    print(f"âœ… {len(test_indices)}ê°œì˜ ëœë¤ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì„ ì • ì™„ë£Œ.")
    print(f"âœ… {len(label_mapping)}ê°œì˜ ë¼ë²¨ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ.")
    
    # --- 3. ì›ë³¸ RoMa ëª¨ë¸ í‰ê°€ ---
    print("\n[2/4] ì›ë³¸ RoMa (DINOv2) í‰ê°€ ì¤‘...")
    
    # ì›ë³¸ RoMa ë””ë ‰í† ë¦¬ë¡œ ì´ë™
    original_cwd = os.getcwd()
    original_dir = os.path.join(original_cwd, 'RoMa_original')
    os.chdir(original_dir)
    
    try:
        sys.path.insert(0, '.')
        from romatch import roma_outdoor
        
        original_model = roma_outdoor(device=device)
        original_model.load_state_dict(torch.load('./checkpoints/roma_outdoor.pth', map_location=device))
        
        original_results = evaluate_model(original_model, test_indices, label_mapping, device, "ì›ë³¸ RoMa (DINOv2)", original_cwd)
        
    finally:
        os.chdir(original_cwd)
    
    # --- 4. DINOv3 RoMa ëª¨ë¸ í‰ê°€ ---
    print("\n[3/4] DINOv3 RoMa í‰ê°€ ì¤‘...")
    
    # DINOv3 ë””ë ‰í† ë¦¬ë¡œ ì´ë™
    dinov3_dir = os.path.join(original_cwd, 'RoMa_dinov3')
    os.chdir(dinov3_dir)
    
    try:
        # sys.pathë¥¼ ì™„ì „íˆ ì¬ì„¤ì •í•˜ì—¬ ì˜¬ë°”ë¥¸ ëª¨ë“ˆ ë¡œë“œ
        import importlib.util
        
        # ê¸°ì¡´ romatch ëª¨ë“ˆë“¤ ì œê±°
        modules_to_remove = [key for key in sys.modules.keys() if key.startswith('romatch')]
        for module in modules_to_remove:
            del sys.modules[module]
        
        # sys.path ì¬ì„¤ì •
        sys.path = [p for p in sys.path if 'RoMa_original' not in p]
        sys.path.insert(0, dinov3_dir)
        
        # DINOv3 ë””ë ‰í† ë¦¬ì˜ roma_models.py íŒŒì¼ ì§ì ‘ ë¡œë“œ
        roma_models_path = os.path.join(dinov3_dir, 'romatch', 'models', 'model_zoo', 'roma_models.py')
        spec = importlib.util.spec_from_file_location("roma_models_dinov3", roma_models_path)
        roma_models_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(roma_models_module)
        
        roma_model = roma_models_module.roma_model
        
        dinov3_model = roma_model(
            resolution=(512, 512),  # DINOv3 íŒ¨ì¹˜ í¬ê¸° 16ì˜ ë°°ìˆ˜ë¡œ ë³€ê²½
            upsample_preds=True,
            device=device,
            weights=None,
            dinov3_model_name="facebook/dinov3-vit7b16-pretrain-sat493m",
            amp_dtype=torch.float32,
            original_roma_weights=os.path.join(original_cwd, 'RoMa_original', 'checkpoints', 'roma_outdoor.pth')
        )
        
        dinov3_results = evaluate_model(dinov3_model, test_indices, label_mapping, device, "DINOv3 RoMa", original_cwd)
        
    finally:
        os.chdir(original_cwd)
    
    # --- 5. ê²°ê³¼ ë¹„êµ ë° ì¶œë ¥ ---
    print("\n[4/4] ê²°ê³¼ ë¹„êµ ë° ë¶„ì„ ì¤‘...")
    print_comparison_results(original_results, dinov3_results)
    
    print("\nğŸŠ ë¹„êµ í‰ê°€ ì™„ë£Œ!")

if __name__ == "__main__":
    compare_models()

